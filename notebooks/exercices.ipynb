{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "# Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préliminaires**: Clone de votre repo et imports"
      ],
      "metadata": {
        "id": "hfkMtaHleKAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/adragneel/exam_2025.git\n",
        "! cp exam_2025/utils/utils_exercices.py .\n",
        "\n"
      ],
      "metadata": {
        "id": "xiD_cI-geJjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b9308b-ca36-4192-f786-5238a379c39b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'exam_2025' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "FWuBKc31YhGH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clef personnelle pour la partie théorique**\n",
        "\n",
        "Dans la cellule suivante, choisir un entier entre 100 et 1000 (il doit être personnel). Cet entier servira de graine au générateur de nombres aléatoire a conserver pour tous les exercices.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3ga_6BNc5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeed = 113"
      ],
      "metadata": {
        "id": "PrCTHM4od5UZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "TRWBLVpCWC06"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "\\\n",
        "\n",
        "**Exercice 1** *Une relation linéaire*\n",
        "\n",
        "La fonction *generate_dataset* fournit deux jeux de données (entraînement et test). Pour chaque jeu de données, la clef 'inputs' donne accès à un tableau numpy (numpy array) de prédicteurs empilés horizontalement : chaque ligne $i$ contient trois prédicteurs $x_i$, $y_i$ et $z_i$. La clef 'targets' renvoie le vecteur des cibles $t_i$. \\\n",
        "\n",
        "Les cibles sont liées aux prédicteurs par le modèle:\n",
        "$$ t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon$$ où $\\epsilon \\sim \\mathcal{N}(0,\\eta)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset, Dataset1\n",
        "train_set, test_set = generate_dataset(mySeed)"
      ],
      "metadata": {
        "id": "gEQmgTI8my8i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Par quelle méthode simple peut-on estimer les coefficients $\\theta_k$ ? La mettre en oeuvre avec la librairie python de votre choix.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q5XZTrXNk12K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Pour estimer les coefficients $\\theta_k$\n",
        "  d'un modèle linéaire, la méthode la plus simple est l'estimation par moindres carrés ordinaires (OLS). Cette méthode minimise la somme des carrés des écarts entre les prédictions du modèle et les valeurs observées des cibles.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "grHAgLV3bTRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming train_set and test_set are defined as in the provided code.\n",
        "X = np.hstack((np.ones((train_set['inputs'].shape[0], 1)), train_set['inputs']))\n",
        "y = train_set['targets']\n",
        "\n",
        "# Use numpy's least squares solver to estimate theta\n",
        "theta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
        "\n",
        "print(\"Estimated coefficients (theta):\", theta)"
      ],
      "metadata": {
        "id": "HITtUqHhFMkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4385735-108e-4154-f37b-bda809b42345"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated coefficients (theta): [5.52416753 1.18625885 1.1083114  2.36999209]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MXGXg8tlPULY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans les cellules suivantes, on se propose d'estimer les $\\theta_k$ grâce à un réseau de neurones entraîné par SGD. Quelle architecture s'y prête ? Justifier en termes d'expressivité et de performances en généralisation puis la coder dans la cellule suivante."
      ],
      "metadata": {
        "id": "CH_Z5ZEIlQPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour estimer les $\\theta_k$\n",
        "à l'aide d'un réseau de neurones entraîné par SGD, une architecture simple et efficace est un réseau de neurones linéaire à une seule couche car Un réseau linéaire sans activation est suffisant pour modéliser une relation linéaire simple  donc ajouter des couches ou des activations augmenterait inutilement la complexité sans gain en expressivité.\n",
        "La simplicité du modèle (absence de surparamétrisation) limite le risque de surapprentissage."
      ],
      "metadata": {
        "id": "ydiyEzbSce1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset et dataloader :\n",
        "dataset = Dataset1(train_set['inputs'], train_set['targets'])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "import torch.nn as nn\n",
        "\n",
        "# A coder :\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear = nn.Linear(3, 1)  # Input features: 3 (x, y, z); Output features: 1 (t)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "oC2BuRLfcGyb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Entraîner cette architecture à la tâche de régression définie par les entrées et sorties du jeu d'entraînement (compléter la cellule ci-dessous)."
      ],
      "metadata": {
        "id": "g6BSTBitpGBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "mySimpleNet = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(mySimpleNet.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = mySimpleNet(batch_inputs)\n",
        "      loss = criterion(outputs.squeeze(), batch_targets)\n",
        "\n",
        "      # Backward pass and optimization\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if (epoch+1) % 100 == 0 :\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Wjfa2Z4RoPO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3127ddb6-883e-4c93-babc-769a570fd75b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/500], Loss: 4.2323\n",
            "Epoch [200/500], Loss: 3.7900\n",
            "Epoch [300/500], Loss: 3.8637\n",
            "Epoch [400/500], Loss: 3.2753\n",
            "Epoch [500/500], Loss: 3.3045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Où sont alors stockées les estimations des  $\\theta_k$ ? Les extraire du réseau *mySimpleNet* dans la cellule suivante."
      ],
      "metadata": {
        "id": "OZwKogEEp2Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The estimated theta_k values are stored in the weights and bias of the linear layer within mySimpleNet.\n",
        "for name, param in mySimpleNet.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "id": "EjgWp1y1rseb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6022e9-72a4-454d-f151-fb21ef45157a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight tensor([[1.1876, 1.1081, 2.3712]])\n",
            "linear.bias tensor([5.5253])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Tester ces estimations sur le jeu de test et comparer avec celles de la question 1. Commentez."
      ],
      "metadata": {
        "id": "pEB-V-oOrJED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use the trained model to make predictions on the test set\n",
        "X_test = torch.tensor(test_set['inputs'], dtype=torch.float32)\n",
        "y_test_pred = mySimpleNet(X_test).detach().numpy()\n",
        "\n",
        "# Assuming 'theta' from Q1 is still in scope\n",
        "X_test_q1 = np.hstack((np.ones((test_set['inputs'].shape[0], 1)), test_set['inputs']))\n",
        "y_test_pred_q1 = np.dot(X_test_q1, theta)\n",
        "\n",
        "# Compare predictions\n",
        "print(\"Predictions from neural network:\", y_test_pred.flatten()[:5])\n",
        "print(\"Predictions from OLS:\", y_test_pred_q1[:5])\n",
        "\n",
        "# Calculate and print Mean Squared Error (MSE) for both methods.\n",
        "mse_nn = np.mean(np.square(y_test_pred.flatten() - test_set['targets']))\n",
        "mse_ols = np.mean(np.square(y_test_pred_q1 - test_set['targets']))\n",
        "\n",
        "print(f\"Mean Squared Error (Neural Network): {mse_nn}\")\n",
        "print(f\"Mean Squared Error (OLS): {mse_ols}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch7ChQZTejOi",
        "outputId": "93825583-a4e1-43d7-8ec4-1ef382bed125"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from neural network: [4.077937  4.392635  6.6639805 8.663747  6.131276 ]\n",
            "Predictions from OLS: [4.07862174 4.39219757 6.66042811 8.66222518 6.12840044]\n",
            "Mean Squared Error (Neural Network): 3.7761703574449137\n",
            "Mean Squared Error (OLS): 3.775926884486523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"L'erreur quadratique moyenne obtenue avec le réseau de neurones est proche de celle obtenue par la méthode analytique\n",
        " Cela montre que le réseau a correctement appris la relation linéaire sous-jacente, bien que les deux approches diffèrent dans leur nature."
      ],
      "metadata": {
        "id": "ELZIC-ECfEZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "VvV2jIrBNtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2** *Champ réceptif et prédiction causale*"
      ],
      "metadata": {
        "id": "CpRvXCaAtsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini dans la cellule suivante est utilisé pour faire le lien entre les valeurs $(x_{t' \\leq t})$ d'une série temporelle d'entrée et la valeur présente $y_t$ d'une série temporelle cible."
      ],
      "metadata": {
        "id": "8JG9wTfK5TBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from utils_exercices import Outconv, Up_causal, Down_causal\n",
        "\n",
        "class Double_conv_causal(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2, with causal convolutions that preserve input size'''\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1):\n",
        "        super(Double_conv_causal, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class causalFCN(nn.Module):\n",
        "    def __init__(self, dilation=1):\n",
        "        super(causalFCN, self).__init__()\n",
        "        size = 64\n",
        "        n_channels = 1\n",
        "        n_classes = 1\n",
        "        self.inc = Double_conv_causal(n_channels, size)\n",
        "        self.down1 = Down_causal(size, 2*size)\n",
        "        self.down2 = Down_causal(2*size, 4*size)\n",
        "        self.down3 = Down_causal(4*size, 8*size, pooling_kernel_size=5, pooling_stride=5)\n",
        "        self.down4 = Down_causal(8*size, 4*size, pooling=False, dilation=2)\n",
        "        self.up2 = Up_causal(4*size, 2*size, kernel_size=5, stride=5)\n",
        "        self.up3 = Up_causal(2*size, size)\n",
        "        self.up4 = Up_causal(size, size)\n",
        "        self.outc = Outconv(size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up2(x5, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "# Exemple d'utilisation\n",
        "model = causalFCN()\n",
        "# Série temporelle d'entrée (x_t):\n",
        "input_tensor1 = torch.rand(1, 1, 10000)\n",
        "# Série temporelle en sortie f(x_t):\n",
        "output = model(input_tensor1)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "fIbU1EJT1MM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f538ad-f8dc-44eb-c26d-4f990ed1351f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** De quel type de réseau de neurones s'agit-il ? Combien de paramètres la couche self.Down1 compte-t-elle (à faire à la main) ?\n",
        "Combien de paramètres le réseau entier compte-t-il (avec un peu de code) ?"
      ],
      "metadata": {
        "id": "-mNnsYU-7R7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il s'agit d'un réseau de neurones convolutionnel causal (Causal Convolutional Neural Network, ou causalCNN)."
      ],
      "metadata": {
        "id": "bNZ8YgNekWbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Nombre de paramètres dans self.Down1:\n",
        "# La couche Down_causal effectue une convolution 1D suivie d'un max pooling.\n",
        "# Convolution:  in_channels * out_channels * kernel_size + out_channels (biais)\n",
        "# Ici, in_channels = 64, out_channels = 128, kernel_size = 3\n",
        "# Donc, nombre de paramètres de la convolution = 64 * 128 * 3 + 128 = 24704\n",
        "\n",
        "\n",
        "\n",
        "# Nombre de paramètres au total:\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Nombre total de paramètres du modèle : {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBXL09NXgW0e",
        "outputId": "c5ed2f3c-bdde-4352-af6e-0b2a43470736"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de paramètres du modèle : 2872641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Par quels mécanismes la taille du vecteur d'entrée est-elle réduite ? Comment est-elle restituée dans la deuxième partie du réseau ?"
      ],
      "metadata": {
        "id": "I4D46A0-8LaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The input size is reduced by the Down_causal layers, which consist of convolutional and max pooling layers.\n",
        "# The convolutional layers reduce the number of features through convolution operation.\n",
        "# The max pooling layers reduce the spatial dimension of the feature maps by downsampling the input.\n",
        "\n",
        "# The size is restored in the second part of the network (the Up_causal layers) primarily using transposed convolutions (also known as deconvolutions).\n",
        "# These operations upsample the feature maps, increasing their spatial dimensions.\n",
        "# Additionally, skip connections from corresponding downsampling layers are often concatenated to the upsampled features.\n",
        "# This helps recover finer details lost during downsampling, improving the quality of the upsampled feature maps.\n"
      ],
      "metadata": {
        "id": "smu75qa3k6zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Par quels mécanismes le champ réceptif est-il augmenté ? Préciser par un calcul la taille du champ réceptif en sortie de *self.inc*."
      ],
      "metadata": {
        "id": "SVNeFnm88yV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Le champ réceptif est augmenté par plusieurs mécanismes dans ce réseau :\n",
        "\n",
        "# 1. Convolutions avec des noyaux de taille supérieure à 1 : Chaque convolution élargit le champ réceptif.\n",
        "# 2. Dilatation : L'utilisation de la dilatation dans les convolutions permet d'élargir le champ réceptif sans augmenter le nombre de paramètres.\n",
        "# 3. Couches de pooling : Les couches de pooling (max-pooling dans ce cas) réduisent la taille de la sortie, mais augmentent le champ réceptif des neurones de la couche suivante.\n",
        "\n",
        "# Calcul de la taille du champ réceptif en sortie de self.inc :\n",
        "# La couche self.inc est composée de deux convolutions 1D avec une dilation de 1 et un noyau de taille 3.\n",
        "\n",
        "# Première convolution :\n",
        "# Champ réceptif = taille du noyau = 3\n",
        "\n",
        "# Deuxième convolution :\n",
        "# Champ réceptif = champ réceptif précédent + (taille du noyau - 1) * dilation\n",
        "# Champ réceptif = 3 + (3-1) * 1 = 5\n",
        "\n",
        "# Donc, le champ réceptif en sortie de self.inc est de 5."
      ],
      "metadata": {
        "id": "wLNwnmBFlLng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Par un bout de code, déterminer empiriquement la taille du champ réceptif associé à la composante $y_{5000}$ du vecteur de sortie. (Indice: considérer les sorties associées à deux inputs qui ne diffèrent que par une composante...)"
      ],
      "metadata": {
        "id": "TVVcBPuA9EP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_tensor1 = torch.rand(1, 1, 10000)  # Séries temporelles d'entrée\n",
        "\n",
        "# Calcul de la sortie pour l'entrée initiale\n",
        "output_original = model(input_tensor1)\n",
        "\n",
        "# Choisir un indice pour tester l'impact (ici on prend l'indice 5000)\n",
        "index = 5000\n",
        "\n",
        "# Créer une copie de l'entrée et modifier légèrement l'élément à l'indice choisi\n",
        "input_tensor_modified = input_tensor1.clone()\n",
        "input_tensor_modified[0, 0, index] += 1e-5  # Modification d'une petite valeur\n",
        "\n",
        "# Calculer la sortie associée à l'entrée modifiée\n",
        "output_modified = model(input_tensor_modified)\n",
        "\n",
        "# Calcul de la différence entre les sorties pour déterminer l'impact\n",
        "output_diff = torch.abs(output_modified - output_original)\n",
        "\n",
        "# Afficher la différence et déterminer l'indice de la sortie affectée\n",
        "print(f\"Differences at index {index} in output:\", output_diff[0, 0, index])\n",
        "\n",
        "# Calcul de la taille du champ réceptif\n",
        "receptive_field_size = torch.sum(output_diff[0, 0, index:] > 1e-5)  # Nombre d'éléments affectés dans la sortie\n",
        "print(f\"Estimated receptive field size for output at index {index}: {receptive_field_size.item()}\")\n"
      ],
      "metadata": {
        "id": "69WMWCSZAg5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9a76e4-f09d-4cc0-adbb-dc02eaf172e5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differences at index 5000 in output: tensor(6.7800e-07, grad_fn=<SelectBackward0>)\n",
            "Estimated receptive field size for output at index 5000: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** $y_{5000}$ dépend-elle des composantes $x_{t, \\space t > 5000}$ ? Justifier de manière empirique puis préciser la partie du code de Double_conv_causal qui garantit cette propriété de \"causalité\" en justifiant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "gZ37skwm-Vpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La difference entre output_original et output_modified est très faible.\n",
        "Cela confirmerait que le réseau respecte la causalité, et que le modèle ne \"regarde\" pas les éléments futurs dans la série temporelle pour prédire y5000."
      ],
      "metadata": {
        "id": "71D8AIF7nJSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "qV52tusgNn6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "Exercice 3: \"Ranknet loss\""
      ],
      "metadata": {
        "id": "bm-sRzmfqc2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un [article récent](https://https://arxiv.org/abs/2403.14144) revient sur les progrès en matière de learning to rank. En voilà un extrait :"
      ],
      "metadata": {
        "id": "Wl8wUjsSM57D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nanopiero/exam_2025/refs/heads/main/utils/png_exercice3.PNG\" alt=\"extrait d'un article\" width=\"800\">"
      ],
      "metadata": {
        "id": "SDZUXMlSDpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Qu'est-ce que les auteurs appellent \"positive samples\" et \"negative samples\" ? Donner un exemple."
      ],
      "metadata": {
        "id": "9NzV1PbMNyuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dans le contexte de l'apprentissage du classement (learning to rank), les \"positive samples\" et \"negative samples\" font référence à des paires d'éléments à classer.\n",
        "\n",
        "# Positive samples: Une paire d'éléments où l'élément positif est considéré comme plus pertinent que l'élément négatif.\n",
        "# Exemple: Dans un moteur de recherche, si une requête donne lieu à deux documents, le document le plus pertinent serait le \"positive sample\", tandis que le moins pertinent serait le \"negative sample\".\n",
        "\n"
      ],
      "metadata": {
        "id": "DNcqOSvKn2sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans l'expression de $\\mathcal{L}_{RankNet}$, d'où proviennent les $z_i$ ? Que représentent-ils ?  "
      ],
      "metadata": {
        "id": "yIKQ5Eo9OnPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dans l'expression de la perte LRankNet, les zi représentent les scores de pertinence prédits par le modèle pour chaque document i.\n",
        "# Ils sont produits par le modèle de classement, qui prend en entrée les caractéristiques des documents et renvoie un score de pertinence pour chaque document.\n",
        "# Plus le score zi est élevé, plus le document i est considéré comme pertinent."
      ],
      "metadata": {
        "id": "XNHwzdRQ7KtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Pourquoi cette expression conduit-elle à ce que, après apprentissage, \"the estimated\n",
        "value of positive samples is greater than that of negative samples\n",
        "for each pair of positive/negative samples\" ?"
      ],
      "metadata": {
        "id": "r74fWiyvPb7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The RankNet loss function aims to minimize the difference between the predicted scores of positive and negative samples.  Specifically, the loss function applies a sigmoid to the difference of the scores of a positive sample ($z_i$) and a negative sample ($z_j$).  The sigmoid function outputs a value between 0 and 1.\n",
        "\n",
        "Let's analyze the loss function:\n",
        "\n",
        "* **When the model correctly ranks the positive sample higher than the negative sample**:  $z_i$ > $z_j$. This leads to a positive input for the sigmoid function. As a result, the sigmoid's output is close to 1. The loss is then close to 0. The model is rewarded.\n",
        "\n",
        "* **When the model incorrectly ranks the negative sample higher than the positive sample**: $z_j$ > $z_i$. This leads to a negative input for the sigmoid function.  The sigmoid's output approaches 0.  The loss function then approaches a value close to log(1) ≈ 0. This implies that the cost associated with this situation is high. Therefore, the model is penalized.\n",
        "\n",
        "* **When the model predicts the same score for both samples ($z_i = z_j$):**  The sigmoid's input is 0, its output is 0.5, and the loss is non-zero.\n",
        "\n",
        "During training, the optimizer adjusts the model's parameters to minimize the overall loss across all sample pairs.  This process essentially pushes the model to assign higher scores ($z_i$) to positive samples and lower scores ($z_j$) to negative samples, ensuring that the difference $z_i - z_j$ is positive, thereby minimizing the loss. This leads to the \"estimated value of positive samples is greater than that of negative samples for each pair\".  Therefore, the model learns to correctly rank samples, favoring the positive ones over the negative ones.\n"
      ],
      "metadata": {
        "id": "E3-PXnPG7kCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Dans le cadre d'une approche par deep learning, quels termes utilise-t-on pour qualifier les réseaux de neurones exploités et la modalité suivant laquelle ils sont entraînés ?"
      ],
      "metadata": {
        "id": "pk1EIi_VVi3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dans le cadre d'une approche par deep learning, on utilise les termes suivants :\n",
        "\n",
        "# Pour qualifier les réseaux de neurones exploités :\n",
        "\n",
        "# - Réseau de neurones convolutifs (CNN) :  spécialement adaptés au traitement des données spatiales (images, vidéos) ou temporelles (signaux, séries temporelles).\n",
        "# - Réseau de neurones récurrents (RNN) : conçus pour traiter des séquences de données, en tenant compte de la dépendance temporelle entre les éléments.\n",
        "# - Réseaux de neurones à transformers (Transformer networks) : une architecture plus récente, très performante pour les tâches de traitement du langage naturel et de plus en plus utilisée pour d'autres types de données.\n",
        "# - Réseau de neurones denses (Fully Connected Network, FCN) : chaque neurone est connecté à tous les neurones de la couche précédente.\n",
        "# - Auto-encodeurs : utilisés pour l'apprentissage non supervisé, afin de réduire la dimensionnalité des données ou de détecter des anomalies.\n",
        "# - Générateurs adversaires (GAN) : deux réseaux antagonistes qui apprennent à générer de nouvelles données similaires aux données d'apprentissage.\n",
        "\n",
        "# Pour la modalité suivant laquelle ils sont entraînés :\n",
        "\n",
        "# - Apprentissage supervisé : le modèle est entraîné sur des données étiquetées, c'est-à-dire que chaque donnée est associée à une cible (label).\n",
        "# - Apprentissage non supervisé : le modèle est entraîné sur des données non étiquetées, afin de découvrir des structures ou des motifs cachés.\n",
        "# - Apprentissage par renforcement : le modèle apprend à interagir avec un environnement, en recevant des récompenses ou des pénalités selon ses actions.\n",
        "# - Apprentissage semi-supervisé : le modèle est entraîné sur un ensemble de données étiquetées et non étiquetées.\n",
        "# - Apprentissage par transfert : utiliser un modèle pré-entraîné sur un grand ensemble de données pour une tâche spécifique et l'adapter pour une tâche différente."
      ],
      "metadata": {
        "id": "bp1Ovc1m7prp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}